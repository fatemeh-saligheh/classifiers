{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#reading data\n",
    "attNames = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\"]\n",
    "FIELD_NAMES = attNames + [\"Class\"]\n",
    "\n",
    "trainData = pd.read_csv('pendigits.tra', names=FIELD_NAMES)\n",
    "testData = pd.read_csv('pendigits.tes', names=FIELD_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(9, 0.0959434214037897), (0, 0.10408326661329063), (7, 0.10381638644248732), (3, 0.0959434214037897), (8, 0.0959434214037897), (6, 0.09607686148919135), (2, 0.10408326661329063), (5, 0.09607686148919135), (1, 0.10394982652788898), (4, 0.10408326661329063)}\n"
     ]
    }
   ],
   "source": [
    "#Estimating the P(C)\n",
    "counts = trainData[\"Class\"].value_counts().to_dict()\n",
    "priors = {(k, v / len(trainData)) for k, v in counts.items()}\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(xi,c):\n",
    "    f = trainData[(trainData['Class'] == c)]\n",
    "    mean = f[xi].mean()\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(xi,c):\n",
    "    f = trainData[(trainData['Class'] == c)]\n",
    "    variance = math.pow(f[xi].std(), 2)\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianProbabilityDensity(x, mean, variance):\n",
    "    if(variance == 0):\n",
    "        variance = 0.000000001\n",
    "    return (1 / (math.sqrt(2 * math.pi * variance))) * (math.exp(-(math.pow(x - mean, 2) / (2 * variance))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def predict():\n",
    "    predictions = []\n",
    "    i = 0\n",
    "    for _, row in testData.iterrows():\n",
    "        i+=1\n",
    "        if(i==1000):\n",
    "            break\n",
    "        results = {}\n",
    "        for c, pc in priors:\n",
    "            sumP = 0\n",
    "            for name in attNames:\n",
    "                \n",
    "                pG = GaussianProbabilityDensity(row[name], mean(name,c), variance(name,c))\n",
    "                if pG > 0:\n",
    "                    sumP += math.log(pG)\n",
    "            results[c] = math.log(pc) + sumP\n",
    "        predictions.append(max(results, key=results.get))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7987987987987988"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy rate for my implemented classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "ytrue = testData[\"Class\"][:999]\n",
    "accuracy_score(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 84,   0,   0,   0,   3,   0,   0,   0,  25,   1],\n",
       "       [  0,  52,  36,   0,   0,  15,   0,   0,   0,   1],\n",
       "       [  0,   8,  88,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   5,   0,  77,   0,   0,   0,   0,   0,   2],\n",
       "       [  0,   0,   0,   0,  93,   3,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,  22,   0,  42,   0,   0,   5,  30],\n",
       "       [  0,   0,   0,   0,   0,   3,  89,   0,   6,   0],\n",
       "       [  0,  15,   0,   0,   0,   1,   0,  90,   1,   3],\n",
       "       [  4,   0,   0,   0,   0,   4,   0,   0, 101,   0],\n",
       "       [  0,   3,   0,   1,   4,   0,   0,   0,   0,  82]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for my implemented classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(trainData[attNames],trainData['Class'])\n",
    "y_pred = []\n",
    "for _, row in testData.iterrows():\n",
    "    y_pred.append(clf.predict([row[attNames]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8224699828473413"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy rate for using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = testData[\"Class\"]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300,   0,   0,   0,   0,   1,   0,   0,  61,   1],\n",
       "       [  0, 196, 116,   0,   1,  49,   0,   1,   0,   1],\n",
       "       [  0,  33, 329,   0,   0,   1,   0,   1,   0,   0],\n",
       "       [  0,  21,   0, 311,   0,   0,   0,   0,   0,   4],\n",
       "       [  0,   0,   0,   0, 357,   5,   0,   0,   0,   2],\n",
       "       [  0,   1,   0,  58,   0, 152,   0,   0,  16, 108],\n",
       "       [  1,   0,   0,   0,   0,  10, 309,   0,  16,   0],\n",
       "       [  0,  45,   1,   0,   0,   6,   0, 295,   6,  11],\n",
       "       [ 10,   0,   0,   0,   0,  11,   0,   0, 315,   0],\n",
       "       [  0,  10,   0,   7,   5,   0,   0,   0,   1, 313]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for using sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
